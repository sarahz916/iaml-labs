{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Support Vector Machine (SVM) Classification and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we initially re-examine the spam filtering problem from Lab 2. This time, we train a Logistic Regression model and a linear Support Vector Machine for the spam or non-spam classification task. In the second part of the lab we examine classification evaluation by using a K-nearest neighbour classifier.\n",
    "\n",
    "\n",
    "All the datasets that you will need for this lab are located within the `datasets` directory (adjacent to this file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from pandas.api.types import CategoricalDtype\n",
    "KNeighboursClassifier = KNeighborsClassifier # For the Brits!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Load `spambase_binary.csv` into a pandas DataFrame structure called `spambase`. Display the number of instances and attributes and the first 5 samples. Remember that the attributes have been binarised. The instances have also been shuffled (i.e. their order has been randomised). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make_binarized</th>\n",
       "      <th>word_freq_address_binarized</th>\n",
       "      <th>word_freq_all_binarized</th>\n",
       "      <th>word_freq_3d_binarized</th>\n",
       "      <th>word_freq_our_binarized</th>\n",
       "      <th>word_freq_over_binarized</th>\n",
       "      <th>word_freq_remove_binarized</th>\n",
       "      <th>word_freq_internet_binarized</th>\n",
       "      <th>word_freq_order_binarized</th>\n",
       "      <th>word_freq_mail_binarized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu_binarized</th>\n",
       "      <th>word_freq_table_binarized</th>\n",
       "      <th>word_freq_conference_binarized</th>\n",
       "      <th>char_freq_;_binarized</th>\n",
       "      <th>char_freq_(_binarized</th>\n",
       "      <th>char_freq_[_binarized</th>\n",
       "      <th>char_freq_!_binarized</th>\n",
       "      <th>char_freq_$_binarized</th>\n",
       "      <th>char_freq_#_binarized</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make_binarized  word_freq_address_binarized  \\\n",
       "0                         0                            1   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   word_freq_all_binarized  word_freq_3d_binarized  word_freq_our_binarized  \\\n",
       "0                        0                       0                        1   \n",
       "1                        0                       0                        0   \n",
       "2                        1                       0                        0   \n",
       "3                        1                       0                        1   \n",
       "4                        0                       0                        1   \n",
       "\n",
       "   word_freq_over_binarized  word_freq_remove_binarized  \\\n",
       "0                         0                           1   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   word_freq_internet_binarized  word_freq_order_binarized  \\\n",
       "0                             1                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          1   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "\n",
       "   word_freq_mail_binarized   ...     word_freq_edu_binarized  \\\n",
       "0                         1   ...                           0   \n",
       "1                         0   ...                           1   \n",
       "2                         0   ...                           0   \n",
       "3                         0   ...                           0   \n",
       "4                         0   ...                           0   \n",
       "\n",
       "   word_freq_table_binarized  word_freq_conference_binarized  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   char_freq_;_binarized  char_freq_(_binarized  char_freq_[_binarized  \\\n",
       "0                      0                      1                      1   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   char_freq_!_binarized  char_freq_$_binarized  char_freq_#_binarized  \\\n",
       "0                      1                      1                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      1                      0                      0   \n",
       "4                      1                      1                      0   \n",
       "\n",
       "   is_spam  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase = pd.read_csv(\"datasets/spambase_binary.csv\")\n",
    "spambase.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.2 ==========\n",
    "We are going to use hold-out validation to evaluate our models below. Split the dataset into training and testing subsets using the `train_test_split` [function](http://scikit-learn.org/0.19/modules/generated/sklearn.cross_validation.train_test_split.html) we have used before. Call the resulting matrices `X_train`, `X_test`, `y_train`, `y_test`. Use 90% of the data for training and the remaining 10% for testing. Make sure you don't include the target variable `is_spam` in the input features (`X_train` / `X_test`)!\n",
    "\n",
    "If you want to be able to reproduce your results exactly, what argument must you remember to set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spambase.drop(columns = \"is_spam\")\n",
    "y = spambase[\"is_spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOU NEED TO SET RANDOM STATE!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "Train a [`LogisticRegression`](http://scikit-learn.org/0.19/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier by using training data. Use the `lbfgs` solver and default settings for the other parameters. Report the classification accuracy on both the training and test sets. Does your classifier generalise well on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = \"lbfgs\")\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58236715, 0.02560386],\n",
       "       [0.03937198, 0.352657  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train = confusion_matrix(y_train, lr.predict(X_train))\n",
    "cm_train = cm_train/y_train.size\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55965293, 0.02819957],\n",
       "       [0.04338395, 0.36876356]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(y_test, lr.predict(X_test))\n",
    "cm_test = cm_test/461\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The generalizer seems to do as well a training data for the test set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.4 ==========\n",
    "Print the coefficients for class 1 for the attributes `word_freq_hp_binarized` and `char_freq_$_binarized`. Generally, we would expect the string `$` to appear in spam, and the string `hp` to appear in non-spam e-mails, as the data was collected from HP Labs. Do the regression coefficients make sense given that class 1 is spam? *Hint: Consider the sigmoid function and how it transforms values into a probability between 0 and 1. Since our attributes are boolean, a positive coefficient can only increase the total sum fed through the sigmoid and thus move the output of the sigmoid towards 1. What can happen if we have continuous, real-valued attributes?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.639347200187697"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = spambase.columns.get_loc(\"word_freq_hp_binarized\")\n",
    "lr.coef_[0,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.698642733252472"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = spambase.columns.get_loc(\"char_freq_$_binarized\")\n",
    "lr.coef_[0,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This suppors that since coefficient for hp is negative, hp is likely to be in non-spam emails. for `$` this means that the character is more likely to be seen in spam emails.For real-valued attributes, if paramter was character count of `$` then more of those characters would push the score towards more likely spam***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.5 ==========\n",
    "Train a [`LinearSVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (i.e. Linear Support Vector classifier) by using default parameters. Report the classification accuracy on the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58188406 0.02608696]\n",
      " [0.03937198 0.352657  ]]\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC()\n",
    "lsvc.fit(X_train, y_train)\n",
    "cm_train = confusion_matrix(y_train, lsvc.predict(X_train))\n",
    "cm_train = cm_train/y_train.size\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55965293 0.02819957]\n",
      " [0.05206074 0.36008677]]\n"
     ]
    }
   ],
   "source": [
    "cm_test = confusion_matrix(y_test, lsvc.predict(X_test))\n",
    "cm_test = cm_test/461\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "What are the coefficients for the attributes `word_freq_hp_binarized` and `char_freq_`$`_binarized`? Compare these to the ones you found with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.856770935597541"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = spambase.columns.get_loc(\"word_freq_hp_binarized\")\n",
    "lsvc.coef_[0,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5693543161872375"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = spambase.columns.get_loc(\"char_freq_$_binarized\")\n",
    "lsvc.coef_[0,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***These coefficents are smaller in scale compared to Logistic Regression since it doesn't go through the sigmond function? ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "How does a linear SVM relate to Logistic Regression? *Hint: Consider the classification boundary learnt in each model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SVM and LR using weights to determine the boundary. LR uses the closeness of a the score to 0 or 1 while SVM uses positive or negative score***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "By using the [`SVC`](http://scikit-learn.org/0.19/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) class train two new support vector classifiers with Gaussian (`rbf`) and polynomial (`poly`) kernels. Again, report classification accuracies on training and test sets and compare with your results from Question 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58405797 0.02391304]\n",
      " [0.04178744 0.35024155]]\n",
      "[[0.56616052 0.02169197]\n",
      " [0.04772234 0.36442516]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = \"rbf\")\n",
    "svc.fit(X_train, y_train)\n",
    "cm_train = confusion_matrix(y_train, svc.predict(X_train))\n",
    "cm_train = cm_train/y_train.size\n",
    "print(cm_train)\n",
    "cm_test = confusion_matrix(y_test, svc.predict(X_test))\n",
    "cm_test = cm_test/461\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60193237 0.00603865]\n",
      " [0.19371981 0.19830918]]\n",
      "[[0.5813449  0.00650759]\n",
      " [0.18438178 0.22776573]]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = \"poly\")\n",
    "svc.fit(X_train, y_train)\n",
    "cm_train = confusion_matrix(y_train, svc.predict(X_train))\n",
    "cm_train = cm_train/y_train.size\n",
    "print(cm_train)\n",
    "cm_test = confusion_matrix(y_test, svc.predict(X_test))\n",
    "cm_test = cm_test/461\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***rbf kernel works the best***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance assessment\n",
    "We will now look at a few ways of assessing the performance of a classifier. To do so we will introduce a new data set, the [Splice](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) data set. The classification task is to identify `intron` and `exon` boundaries on gene sequences. For more information, you can read the dataset description in the link. The class attribute can take on 3 values: `N`, `IE` and `EI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "Load the `splice_train.csv` and `splice_test.csv` into two separate dataframes. Display the shape and first 10 instances for each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    T    G    A    T    G    C    C    T    G    C  ...      C     C     C   \n",
       "1    G    C    C    C    A    T    A    T    T    C  ...      T     G     G   \n",
       "2    G    G    C    T    G    C    C    G    G    A  ...      A     C     T   \n",
       "3    C    T    G    C    T    G    C    T    G    G  ...      G     G     C   \n",
       "4    T    C    C    C    C    G    A    G    C    C  ...      A     T     C   \n",
       "5    A    T    A    C    C    T    G    C    C    C  ...      A     T     G   \n",
       "6    T    T    C    T    C    C    A    T    T    T  ...      G     A     T   \n",
       "7    A    A    A    G    A    T    G    A    T    A  ...      A     A     G   \n",
       "8    C    C    A    A    T    C    C    C    A    G  ...      G     G     C   \n",
       "9    G    C    C    G    T    G    G    T    T    T  ...      A     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     C     C     T     G     A     G     N  \n",
       "1     A     C     T     T     C     C     N  \n",
       "2     G     T     G     T     C     T    EI  \n",
       "3     T     G     C     T     G     G    EI  \n",
       "4     A     G     C     G     C     A     N  \n",
       "5     G     G     G     T     C     T    EI  \n",
       "6     A     T     C     C     A     T    IE  \n",
       "7     C     C     C     T     T     C    EI  \n",
       "8     G     G     C     C     T     G     N  \n",
       "9     G     C     T     C     C     T    EI  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Splice Train Here\n",
    "splice_train = pd.read_csv(\"datasets/splice_train.csv\")\n",
    "# Your Code goes here:\n",
    "splice_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "      <th>pos4</th>\n",
       "      <th>pos5</th>\n",
       "      <th>pos6</th>\n",
       "      <th>pos7</th>\n",
       "      <th>pos8</th>\n",
       "      <th>pos9</th>\n",
       "      <th>...</th>\n",
       "      <th>pos51</th>\n",
       "      <th>pos52</th>\n",
       "      <th>pos53</th>\n",
       "      <th>pos54</th>\n",
       "      <th>pos55</th>\n",
       "      <th>pos56</th>\n",
       "      <th>pos57</th>\n",
       "      <th>pos58</th>\n",
       "      <th>pos59</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos0 pos1 pos2 pos3 pos4 pos5 pos6 pos7 pos8 pos9  ...  pos51 pos52 pos53  \\\n",
       "0    C    C    C    T    C    C    C    A    C    T  ...      C     C     C   \n",
       "1    C    A    C    T    G    A    G    T    T    G  ...      G     A     A   \n",
       "2    C    A    G    A    C    T    G    G    G    T  ...      A     G     A   \n",
       "3    A    G    T    G    A    T    T    G    A    C  ...      T     A     C   \n",
       "4    G    T    A    G    A    C    A    C    C    T  ...      A     T     C   \n",
       "5    C    T    T    G    T    T    A    C    A    G  ...      C     C     G   \n",
       "6    C    G    T    C    A    A    T    C    A    A  ...      A     A     A   \n",
       "7    G    T    C    C    G    T    G    C    C    T  ...      G     C     C   \n",
       "8    A    T    A    C    C    T    G    T    A    G  ...      C     G     T   \n",
       "9    G    G    T    G    G    G    C    C    A    A  ...      C     A     G   \n",
       "\n",
       "  pos54 pos55 pos56 pos57 pos58 pos59 class  \n",
       "0     A     G     T     G     C     A    IE  \n",
       "1     C     C     A     G     T     G     N  \n",
       "2     C     C     A     C     A     G    EI  \n",
       "3     C     A     A     A     G     A     N  \n",
       "4     C     C     T     T     C     T    IE  \n",
       "5     A     G     A     A     C     C     N  \n",
       "6     A     T     T     A     A     G    EI  \n",
       "7     C     T     T     T     G     C     N  \n",
       "8     T     T     A     T     A     T     N  \n",
       "9     G     C     A     T     G     G     N  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Splice Test Here\n",
    "splice_test = pd.read_csv(\"datasets/splice_test.csv\")\n",
    "# Your Code goes here:\n",
    "splice_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ========== \n",
    "Convert the categorical attributes into numeric ones by using the [`get_dummies(...)`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.get_dummies.html) function from pandas. Make sure to take care of the values `D`, `N`, `S`, `R` (see the [documentation](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29) for the data). *Hint: checkout the pandas [`CategoricalDtype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.api.types.CategoricalDtype.html#pandas.api.types.CategoricalDtype)*. Also, make sure to not transform the target variable (`class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoricalDtype(categories=['D', 'N', 'S', 'A', 'G', 'T', 'C'], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = splice_train.drop(columns = \"class\")\n",
    "y_train = splice_train[\"class\"]\n",
    "X_test = splice_test.drop(columns=\"class\")\n",
    "y_test = splice_test[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D: A or G or T\n",
    "N: A or G or C or T\n",
    "S: C or G\n",
    "R: A or G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0_D</th>\n",
       "      <th>pos0_N</th>\n",
       "      <th>pos0_S</th>\n",
       "      <th>pos0_A</th>\n",
       "      <th>pos0_G</th>\n",
       "      <th>pos0_T</th>\n",
       "      <th>pos0_C</th>\n",
       "      <th>pos1_D</th>\n",
       "      <th>pos1_N</th>\n",
       "      <th>pos1_S</th>\n",
       "      <th>...</th>\n",
       "      <th>pos58_G</th>\n",
       "      <th>pos58_T</th>\n",
       "      <th>pos58_C</th>\n",
       "      <th>pos59_D</th>\n",
       "      <th>pos59_N</th>\n",
       "      <th>pos59_S</th>\n",
       "      <th>pos59_A</th>\n",
       "      <th>pos59_G</th>\n",
       "      <th>pos59_T</th>\n",
       "      <th>pos59_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos0_D  pos0_N  pos0_S  pos0_A  pos0_G  pos0_T  pos0_C  pos1_D  pos1_N  \\\n",
       "0       0       0       0       0       0       1       0       0       0   \n",
       "1       0       0       0       0       1       0       0       0       0   \n",
       "2       0       0       0       0       1       0       0       0       0   \n",
       "3       0       0       0       0       0       0       1       0       0   \n",
       "4       0       0       0       0       0       1       0       0       0   \n",
       "\n",
       "   pos1_S   ...     pos58_G  pos58_T  pos58_C  pos59_D  pos59_N  pos59_S  \\\n",
       "0       0   ...           0        0        0        0        0        0   \n",
       "1       0   ...           0        0        1        0        0        0   \n",
       "2       0   ...           0        0        1        0        0        0   \n",
       "3       0   ...           1        0        0        0        0        0   \n",
       "4       0   ...           0        0        1        0        0        0   \n",
       "\n",
       "   pos59_A  pos59_G  pos59_T  pos59_C  \n",
       "0        0        1        0        0  \n",
       "1        0        0        0        1  \n",
       "2        0        0        1        0  \n",
       "3        0        1        0        0  \n",
       "4        1        0        0        0  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(t)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos0_D</th>\n",
       "      <th>pos0_N</th>\n",
       "      <th>pos0_S</th>\n",
       "      <th>pos0_A</th>\n",
       "      <th>pos0_G</th>\n",
       "      <th>pos0_T</th>\n",
       "      <th>pos0_C</th>\n",
       "      <th>pos1_D</th>\n",
       "      <th>pos1_N</th>\n",
       "      <th>pos1_S</th>\n",
       "      <th>...</th>\n",
       "      <th>pos58_G</th>\n",
       "      <th>pos58_T</th>\n",
       "      <th>pos58_C</th>\n",
       "      <th>pos59_D</th>\n",
       "      <th>pos59_N</th>\n",
       "      <th>pos59_S</th>\n",
       "      <th>pos59_A</th>\n",
       "      <th>pos59_G</th>\n",
       "      <th>pos59_T</th>\n",
       "      <th>pos59_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos0_D  pos0_N  pos0_S  pos0_A  pos0_G  pos0_T  pos0_C  pos1_D  pos1_N  \\\n",
       "0       0       0       0       0       0       0       1       0       0   \n",
       "1       0       0       0       0       0       0       1       0       0   \n",
       "2       0       0       0       0       0       0       1       0       0   \n",
       "3       0       0       0       1       0       0       0       0       0   \n",
       "4       0       0       0       0       1       0       0       0       0   \n",
       "\n",
       "   pos1_S   ...     pos58_G  pos58_T  pos58_C  pos59_D  pos59_N  pos59_S  \\\n",
       "0       0   ...           0        0        1        0        0        0   \n",
       "1       0   ...           0        1        0        0        0        0   \n",
       "2       0   ...           0        0        0        0        0        0   \n",
       "3       0   ...           1        0        0        0        0        0   \n",
       "4       0   ...           0        0        1        0        0        0   \n",
       "\n",
       "   pos59_A  pos59_G  pos59_T  pos59_C  \n",
       "0        1        0        0        0  \n",
       "1        0        1        0        0  \n",
       "2        0        1        0        0  \n",
       "3        1        0        0        0  \n",
       "4        0        0        1        0  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.astype(t)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Store the training and testing data into numpy arrays `X_train`, `y_train`, `X_test` and `y_test`. Display the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2935, 420)\n",
      "(2935,)\n",
      "(255, 420)\n",
      "(255,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ==========\n",
    "Familiarise yourself with [Nearest Neighbours Classification](http://scikit-learn.org/0.19/modules/neighbors.html#classification). Use a [`KNeighborsClassifier`](http://scikit-learn.org/0.19/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "by using a single neighbour. Report the classification accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.43611584e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.43270869e-01 0.00000000e+00]\n",
      " [0.00000000e+00 3.40715503e-04 5.12776831e-01]]\n",
      "0.9996592844974446\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors=1)\n",
    "knc.fit(X_train, y_train)\n",
    "cm_train = confusion_matrix(y_train, knc.predict(X_train))\n",
    "cm_train = cm_train/y_train.size\n",
    "print(cm_train)\n",
    "print(np.trace(cm_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5 ==========\n",
    "Is the above result meaningful? Why is testing on the training data a particularly bad idea for a 1-nearest neighbour classifier? Do you expect the performance of the classifier on a test set to be as good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I think for 1-nearest neighbour might be overfit to the training data :( Test performance will not be good***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "Now report the classification accuracy on the test set and check your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2        0.00392157 0.        ]\n",
      " [0.01568627 0.16862745 0.02745098]\n",
      " [0.10196078 0.10196078 0.38039216]]\n",
      "0.7490196078431373\n"
     ]
    }
   ],
   "source": [
    "cm_test = confusion_matrix(y_test, knc.predict(X_test))\n",
    "cm_test = cm_test/y_test.size\n",
    "print(cm_test)\n",
    "print(np.trace(cm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Plot a histogram of the target variable (i.e. `class`) in the test set. *Hint: matplotlib won't allow you to plot a histogram for categorical values. Instead, you can use Pandas' built-in bar plot tool in conjunction with the [`value_counts`](http://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.value_counts.html).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N     149\n",
       "IE     54\n",
       "EI     52\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = y_test.value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([1, 2, 3], count, tick_label = [\"N\", \"IE\", \"EI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "What would be the accuracy of the classifier, if all points were labelled as `N`? \n",
    "\n",
    "**Pro Tip** - You should always use a ['Dummy Model'](http://scikit-learn.org/0.19/modules/model_evaluation.html#dummy-estimators) (a ridiculously simple model) like this to compare with your 'real' models. It's very common for complex models to be outperformed by a simple model, such as predicting the most common class. When complex models are outperformed by 'Dummies', you should investigate why: often there was an issue with the code, the data, or the way the model works was misunderstood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5843137254901961"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "149/y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "Now we want to explore the effect of the `k` parameter. To do this, train the classifier multiple times, each time setting the KNN option to a different value. Try `5`, `10`, `50`, `100`, `200`, `500`, `1000`, `1500` and `2000` and test the classifier on the test set. How does the k parameter effect the results? *Hint: Consider how well the classifier is generalising to previously unseen data, and how it compares to the dumb prediction accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_test (n):\n",
    "    knc = KNeighborsClassifier(n_neighbors=n)\n",
    "    knc.fit(X_train, y_train)\n",
    "    cm_test = confusion_matrix(y_test, knc.predict(X_test))\n",
    "    cm_test = cm_test/y_test.size\n",
    "    #print(cm_test)\n",
    "    print(np.trace(cm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7686274509803921\n",
      "0.7960784313725491\n",
      "0.8627450980392157\n",
      "0.8941176470588235\n",
      "0.9058823529411765\n",
      "0.9529411764705883\n",
      "0.9529411764705883\n",
      "0.6980392156862746\n",
      "0.5843137254901961\n"
     ]
    }
   ],
   "source": [
    "k_test(5)\n",
    "k_test(10)\n",
    "k_test(50)\n",
    "k_test(100)\n",
    "k_test(200)\n",
    "k_test(500)\n",
    "k_test(1000)\n",
    "k_test(1500)\n",
    "k_test(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Greater neighbors ==> dumber model but there is a sweet spot at n = 500***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "Plot the results (k-value on the x-axis and classification accuracy on the y-axis), making sure to mark the axes. Can you conclude anything from observing the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x137d445e488>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = [0.7686274509803921,0.7960784313725491,0.8627450980392157,0.8941176470588235,0.9058823529411765,0.9529411764705883,0.9529411764705883,0.6980392156862746,0.5843137254901961]\n",
    "plt.plot([5, 10, 50, 100, 200, 500, 1000, 1500, 2000], acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***There's most def a sweet spot in the middle at n = 500***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "Select best value for `k` from Questions 2.9 and 2.10 and plot the normalised confusion matrix on the test set (you may use the provided function). Then plot the confusion matrix for a 5-nearest neighbour classifier. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 500\n",
    "knc = KNeighborsClassifier(n_neighbors=n)\n",
    "knc.fit(X_train, y_train)\n",
    "cm_test = confusion_matrix(y_test, knc.predict(X_test))\n",
    "cm_test = cm_test/y_test.size\n",
    "plot_confusion_matrix(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pretty good confusion matrix?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "Read about the [logarithimic loss](http://scikit-learn.org/0.19/modules/generated/sklearn.metrics.log_loss.html) (or cross-entropy loss). It is often the error metric used when we are trying to optimise classification models.\n",
    "\n",
    "This metric takes as input the true labels and the estimated probability distributions (bernouli or multinomial). It makes sense to use this metric when we are interested not only in the predicted labels, but also in the confidence with which these labels are predicted.\n",
    "\n",
    "For instance, think of the situation where you have a single test point and two classifiers. Both classifiers predict the label correctly, however classifier A predicts that the test point belongs to the class with probability 0.55, whereas classifier B predicts the correct class with probability 0.99. Classification accuracy would be the same for the two classifiers (why?) but the `log_loss` metric would indicate that classifier B should be favoured.\n",
    "\n",
    "Produce a scatter plot similar to the one in Question 2.10 but this time show `log_loss` on your y axis. Which value for `k` would you pick if `log_loss` was the error metric? Comment on why this might happen, and which metric would be a better evaluator of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lst = [5, 10, 50, 100, 200, 500, 1000, 1500, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss (n):\n",
    "    knc = KNeighborsClassifier(n_neighbors=n)\n",
    "    knc.fit(X_train, y_train)\n",
    "    prob = knc.predict_proba(X_test)\n",
    "    return log_loss(y_test, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []\n",
    "for n in n_lst:\n",
    "    ll.append(get_loss(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x137d4ada588>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_lst, ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***a good ole elbow plot that we love, 100 woud be better ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 ==========\n",
    "\n",
    "Could you use the `log_loss` metric to evaluate the performance of an SVM classifier? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***No bc SVM is a discriminatory model and not a generative one***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
